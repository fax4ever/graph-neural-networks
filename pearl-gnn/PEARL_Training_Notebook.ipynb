{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# PEARL: Positional Encodings Augmented with Representation Learning\n",
    "## Training on ZINC Dataset\n",
    "\n",
    "This notebook demonstrates the implementation and training of PEARL (Positional Encodings Augmented with Representation Learning) on the ZINC molecular property prediction dataset.\n",
    "\n",
    "**Paper**: Learning Efficient Positional Encodings with Graph Neural Networks (Kanatsoulis et al., 2025)\n",
    "\n",
    "**Key Features**:\n",
    "- Efficient positional encoding generation via message passing\n",
    "- R-PEARL: Random sampling-based PE (O(N) complexity)\n",
    "- B-PEARL: Basis vectors-based PE (O(N²) complexity)\n",
    "- Stable and expressive graph representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch and PyTorch Geometric\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install torch-geometric\n",
    "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install matplotlib networkx numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, global_add_pool\n",
    "from torch_geometric.data import Data, Batch, DataLoader\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.utils import get_laplacian, to_dense_adj\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyperparams"
   },
   "source": [
    "## 2. HyperParameters Configuration\n",
    "\n",
    "Define all hyperparameters for the model and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyperparams-code"
   },
   "outputs": [],
   "source": [
    "class HyperParam:\n",
    "    # Dataset properties (ZINC specific)\n",
    "    n_node_types: int = 28  # Number of atom types in ZINC\n",
    "    n_edge_types: int = 3   # Number of bond types in ZINC\n",
    "\n",
    "    # General hyperparameters\n",
    "    seed: int = 42\n",
    "    device: torch.device\n",
    "    device_name: str\n",
    "\n",
    "    # Model > MLP hyperparameters\n",
    "    n_mlp_layers: int = 3\n",
    "    mlp_hidden_dims: int = 128\n",
    "    mlp_dropout_prob: float = 0.0\n",
    "    mlp_norm_type: str = \"batch\"\n",
    "\n",
    "    # Model > GINE hyperparameters\n",
    "    n_base_layers: int = 4\n",
    "    node_emb_dims: int = 128\n",
    "    base_hidden_dims: int = 128\n",
    "    gine_model_bn: bool = False\n",
    "    pooling: str = \"add\"\n",
    "    target_dim: int = 1\n",
    "\n",
    "    # Model > GIN / SampleAggregator hyperparameters\n",
    "    gin_sample_aggregator_bn: bool = True\n",
    "    n_sample_aggr_layers: int = 8\n",
    "    sample_aggr_hidden_dims: int = 40\n",
    "\n",
    "    # Model > Positional Encoding / PEARL\n",
    "    pe_dims: int = 37  # Based on SPE paper (Huang et al., 2023)\n",
    "    basis: bool = False  # False for R-PEARL, True for B-PEARL\n",
    "    num_samples: int = 120  # Number of samples for R-PEARL\n",
    "    pearl_k: int = 7  # Polynomial filter order\n",
    "    pearl_mlp_nlayers: int = 1\n",
    "    pearl_mlp_hid: int = 37\n",
    "    pearl_mlp_out: int = 37\n",
    "\n",
    "    # Dataset hyperparameters\n",
    "    use_subset: bool = True  # Use ZINC subset (12K graphs) or full (250K)\n",
    "    train_batch_size: int = 32\n",
    "    val_batch_size: int = 32\n",
    "    test_batch_size: int = 32\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-6\n",
    "    num_epochs: int = 10  # Set to 1400 for full training (as in paper)\n",
    "    n_warmup_steps: int = 100\n",
    "    \n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            self.device_name = torch.cuda.get_device_name(0)\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            self.device_name = \"CPU\"\n",
    "        self.set_seed()\n",
    "\n",
    "    def set_seed(self) -> None:\n",
    "        \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed_all(self.seed)\n",
    "\n",
    "# Initialize hyperparameters\n",
    "hp = HyperParam()\n",
    "print(f\"Device: {hp.device}\")\n",
    "print(f\"Device name: {hp.device_name}\")\n",
    "print(f\"Using {'ZINC subset (12K)' if hp.use_subset else 'Full ZINC (250K)'}\")\n",
    "print(f\"Mode: {'R-PEARL' if not hp.basis else 'B-PEARL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-components"
   },
   "source": [
    "## 3. Model Components\n",
    "\n",
    "### 3.1 MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlp"
   },
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, in_dims: int, out_dims: int, hp: HyperParam):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_dims, out_dims)\n",
    "        self.normalization = nn.BatchNorm1d(out_dims) if hp.mlp_norm_type == \"batch\" else nn.LayerNorm(out_dims)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=hp.mlp_dropout_prob)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, mask=None) -> torch.Tensor:\n",
    "        X = self.linear(X)\n",
    "        if mask is not None:\n",
    "            X[~mask] = 0\n",
    "\n",
    "        if mask is None:\n",
    "            shape = X.size()\n",
    "            X = X.reshape(-1, shape[-1])\n",
    "            X = self.normalization(X)\n",
    "            X = X.reshape(shape)\n",
    "        else:\n",
    "            X[mask] = self.normalization(X[mask])\n",
    "\n",
    "        X = self.activation(X)\n",
    "        X = self.dropout(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dims: int, out_dims: int, hp: HyperParam):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(hp.n_mlp_layers - 1):\n",
    "            self.layers.append(MLPLayer(in_dims, hp.mlp_hidden_dims, hp))\n",
    "            in_dims = hp.mlp_hidden_dims\n",
    "        self.linear = nn.Linear(hp.mlp_hidden_dims, out_dims)\n",
    "        self.dropout = nn.Dropout(p=hp.mlp_dropout_prob)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, mask=None) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, mask=mask)\n",
    "        X = self.linear(X)\n",
    "        X = self.dropout(X)\n",
    "        return X\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.linear.out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gin"
   },
   "source": [
    "### 3.2 GIN (Graph Isomorphism Network)\n",
    "\n",
    "GIN layers for processing positional encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gin-code"
   },
   "outputs": [],
   "source": [
    "class GINLayer(MessagePassing):\n",
    "    def __init__(self, in_dims: int, out_dims: int, hp: HyperParam):\n",
    "        super(GINLayer, self).__init__(aggr=\"add\", node_dim=0)\n",
    "        self.eps = nn.Parameter(data=torch.randn(1))\n",
    "        self.mlp = MLP(in_dims, out_dims, hp)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, edge_index: torch.Tensor, mask=None) -> torch.Tensor:\n",
    "        S = self.propagate(edge_index, X=X)\n",
    "        Z = (1 + self.eps) * X + S\n",
    "        return self.mlp(Z, mask=mask)\n",
    "    \n",
    "    def message(self, X_j: torch.Tensor) -> torch.Tensor:\n",
    "        return X_j\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.mlp.out_dims\n",
    "\n",
    "\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, hp: HyperParam, residual: bool = False):\n",
    "        super(GIN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList() if hp.gin_sample_aggregator_bn else None\n",
    "        self.residual = residual\n",
    "        \n",
    "        in_dims = hp.pearl_mlp_out\n",
    "        for _ in range(hp.n_sample_aggr_layers - 1):\n",
    "            self.layers.append(GINLayer(in_dims, hp.sample_aggr_hidden_dims, hp))\n",
    "            in_dims = hp.sample_aggr_hidden_dims\n",
    "            if self.batch_norms is not None:\n",
    "                self.batch_norms.append(nn.BatchNorm1d(hp.sample_aggr_hidden_dims))\n",
    "\n",
    "        self.layers.append(GINLayer(hp.sample_aggr_hidden_dims, hp.pe_dims, hp))\n",
    "\n",
    "    def forward(self, X: torch.Tensor, edge_index: torch.Tensor, mask=None) -> torch.Tensor:\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            X0 = X\n",
    "            X = layer(X, edge_index, mask=mask)\n",
    "            if mask is not None:\n",
    "                X[~mask] = 0\n",
    "            if self.batch_norms is not None and i < len(self.layers) - 1:\n",
    "                if mask is None:\n",
    "                    X = self.batch_norms[i](X.transpose(2, 1)).transpose(2, 1) if X.ndim == 3 else self.batch_norms[i](X)\n",
    "                else:\n",
    "                    X[mask] = self.batch_norms[i](X[mask])\n",
    "            if self.residual:\n",
    "                X = X + X0\n",
    "        return X\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.layers[-1].out_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "positional-encoding"
   },
   "source": [
    "### 3.3 Positional Encoding (PEARL)\n",
    "\n",
    "The core PEARL implementation with R-PEARL and B-PEARL variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe-utils"
   },
   "outputs": [],
   "source": [
    "def add_laplacian_transform(data: Data) -> Data:\n",
    "    \"\"\"Pre-compute sparse Laplacian for each graph.\"\"\"\n",
    "    n = data.num_nodes\n",
    "    L_edge_index, L_values = get_laplacian(data.edge_index, normalization=\"sym\", num_nodes=n)\n",
    "    data.lap_edge_index = L_edge_index\n",
    "    data.lap_edge_attr = L_values\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_per_graph_dense_laplacians(batch: Batch) -> List[torch.Tensor]:\n",
    "    \"\"\"Extract per-graph dense Laplacians from batched graph.\"\"\"\n",
    "    num_graphs = batch.num_graphs\n",
    "    ptr = batch.ptr\n",
    "    lap_edge_slices = batch._slice_dict['lap_edge_index']\n",
    "    lap_attr_slices = batch._slice_dict['lap_edge_attr']\n",
    "    \n",
    "    laplacians = []\n",
    "    for i in range(num_graphs):\n",
    "        n_nodes = ptr[i + 1] - ptr[i]\n",
    "        node_offset = ptr[i].item()\n",
    "        edge_start = lap_edge_slices[i].item()\n",
    "        edge_end = lap_edge_slices[i + 1].item()\n",
    "        graph_lap_edge_index = batch.lap_edge_index[:, edge_start:edge_end] - node_offset\n",
    "        attr_start = lap_attr_slices[i].item()\n",
    "        attr_end = lap_attr_slices[i + 1].item()\n",
    "        graph_lap_edge_attr = batch.lap_edge_attr[attr_start:attr_end]\n",
    "        dense_lap = to_dense_adj(\n",
    "            graph_lap_edge_index, \n",
    "            edge_attr=graph_lap_edge_attr, \n",
    "            max_num_nodes=n_nodes\n",
    "        ).squeeze(0)\n",
    "        laplacians.append(dense_lap)\n",
    "    return laplacians\n",
    "\n",
    "\n",
    "def initial_pe(batch: Batch, basis: bool, num_samples: int) -> List[torch.Tensor]:\n",
    "    \"\"\"Initialize PE basis (identity for B-PEARL, random for R-PEARL).\"\"\"\n",
    "    ptr = batch.ptr\n",
    "    num_graphs = batch.num_graphs\n",
    "    device = batch.x.device\n",
    "    W_list = []\n",
    "    for i in range(num_graphs):\n",
    "        n_nodes = (ptr[i + 1] - ptr[i]).item()\n",
    "        W = torch.eye(n_nodes, device=device) if basis else torch.randn(n_nodes, num_samples, device=device)\n",
    "        W_list.append(W)\n",
    "    return W_list\n",
    "\n",
    "\n",
    "def filter(S, W, k):\n",
    "    \"\"\"Apply polynomial filter: [W, SW, S²W, ..., S^(k-1)W]\"\"\"\n",
    "    out = W\n",
    "    w_list = [out.unsqueeze(-1)]\n",
    "    for i in range(k - 1):\n",
    "        out = S @ out\n",
    "        w_list.append(out.unsqueeze(-1))\n",
    "    return torch.cat(w_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe-aggregators"
   },
   "outputs": [],
   "source": [
    "class RandomSampleAggregator(nn.Module):\n",
    "    \"\"\"R-PEARL: Aggregate random samples with averaging.\"\"\"\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(RandomSampleAggregator, self).__init__()\n",
    "        self.gin = GIN(hp)\n",
    "        self.mlp = MLP(hp.pe_dims, hp.pe_dims, hp)\n",
    "        self.running_sum = 0\n",
    "\n",
    "    def forward(self, W_list: List[torch.Tensor], edge_index: torch.Tensor, final=True) -> torch.Tensor:\n",
    "        W = torch.cat(W_list, dim=0)\n",
    "        PE = self.gin(W, edge_index)\n",
    "        PE = PE.sum(dim=1)\n",
    "        self.running_sum += PE\n",
    "        if final:\n",
    "            PE = self.running_sum\n",
    "            self.running_sum = 0\n",
    "        return PE\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.gin.out_dims\n",
    "\n",
    "\n",
    "class BasisSampleAggregator(nn.Module):\n",
    "    \"\"\"B-PEARL: Aggregate basis vectors with summation pooling.\"\"\"\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(BasisSampleAggregator, self).__init__()\n",
    "        self.gin = GIN(hp)\n",
    "        self.mlp = MLP(hp.pe_dims, hp.pe_dims, hp)\n",
    "\n",
    "    def forward(self, W_list: List[torch.Tensor], edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        n_max = max(W.size(0) for W in W_list)\n",
    "        W_pad_list, mask = [], []\n",
    "        for W in W_list:\n",
    "            zeros = torch.zeros(W.size(0), n_max - W.size(1), W.size(2), device=W.device)\n",
    "            W_pad_list.append(torch.cat([W, zeros], dim=1))\n",
    "            mask.append((torch.arange(n_max, device=W.device) < W.size(0)).tile((W.size(0), 1)))\n",
    "        W = torch.cat(W_pad_list, dim=0)\n",
    "        mask = torch.cat(mask, dim=0)\n",
    "        PE = self.gin(W, edge_index, mask=mask)\n",
    "        return (PE * mask.unsqueeze(-1)).sum(dim=1)\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.gin.out_dims\n",
    "\n",
    "\n",
    "class PEARLPositionalEncoder(nn.Module):\n",
    "    \"\"\"PEARL Positional Encoder with polynomial filtering.\"\"\"\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(PEARLPositionalEncoder, self).__init__()\n",
    "        self.sample_aggr = BasisSampleAggregator(hp) if hp.basis else RandomSampleAggregator(hp)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(\n",
    "                hp.pearl_k if i == 0 else hp.pearl_k,\n",
    "                hp.pearl_mlp_hid if i < hp.pearl_mlp_nlayers - 1 else hp.pearl_mlp_out\n",
    "            ) for i in range(hp.pearl_mlp_nlayers)\n",
    "        ])\n",
    "        self.norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hp.pearl_mlp_hid if i < hp.pearl_mlp_nlayers - 1 else hp.pearl_mlp_out)\n",
    "            for i in range(hp.pearl_mlp_nlayers)\n",
    "        ])\n",
    "        self.activation = nn.ReLU()\n",
    "        self.k = hp.pearl_k\n",
    "        self.basis = hp.basis\n",
    "        self.num_samples = hp.num_samples\n",
    "\n",
    "    def forward(self, batch: Batch) -> torch.Tensor:\n",
    "        Lap_list = get_per_graph_dense_laplacians(batch)\n",
    "        edge_index = batch.edge_index\n",
    "        W_init = initial_pe(batch, self.basis, self.num_samples)\n",
    "\n",
    "        W_list = []\n",
    "        for lap, w in zip(Lap_list, W_init):\n",
    "            output = filter(lap, w, self.k)\n",
    "            if len(self.layers) > 0:\n",
    "                for layer, bn in zip(self.layers, self.norms):\n",
    "                    output = output.transpose(0, 1)\n",
    "                    output = layer(output)\n",
    "                    output = bn(output.transpose(1, 2)).transpose(1, 2)\n",
    "                    output = self.activation(output)\n",
    "                    output = output.transpose(0, 1)\n",
    "            W_list.append(output)\n",
    "        return self.sample_aggr(W_list, edge_index)\n",
    "\n",
    "    @property\n",
    "    def out_dims(self) -> int:\n",
    "        return self.sample_aggr.out_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gine"
   },
   "source": [
    "### 3.4 GINE (Graph Isomorphism Network with Edge features)\n",
    "\n",
    "The base GNN model that processes graphs with edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gine-code"
   },
   "outputs": [],
   "source": [
    "class GINELayer(MessagePassing):\n",
    "    def __init__(self, in_dims: int, out_dims: int, hp: HyperParam):\n",
    "        super(GINELayer, self).__init__(aggr=\"add\", node_dim=0)\n",
    "        self.edge_features = nn.Embedding(hp.n_edge_types + 1, in_dims)\n",
    "        self.pe_embedding = MLP(hp.pe_dims, in_dims, hp)\n",
    "        self.eps = nn.Parameter(data=torch.randn(1))\n",
    "        self.mlp = MLP(in_dims, out_dims, hp)\n",
    "\n",
    "    def forward(self, X_n: torch.Tensor, edge_index: torch.Tensor,\n",
    "                edge_attr: torch.Tensor, PE: torch.Tensor) -> torch.Tensor:\n",
    "        X_e = self.edge_features(edge_attr)\n",
    "        X_n = X_n + self.pe_embedding(PE)\n",
    "        S = self.propagate(edge_index, X=X_n, X_e=X_e)\n",
    "        Z = (1 + self.eps) * X_n + S\n",
    "        return self.mlp(Z)\n",
    "\n",
    "    def message(self, X_j: torch.Tensor, X_e: torch.Tensor) -> torch.Tensor:\n",
    "        return F.relu(X_j + X_e)\n",
    "\n",
    "\n",
    "class GINE(nn.Module):\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(GINE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList() if hp.gine_model_bn else None\n",
    "\n",
    "        in_dims = hp.node_emb_dims\n",
    "        for _ in range(hp.n_base_layers - 1):\n",
    "            self.layers.append(GINELayer(in_dims, hp.base_hidden_dims, hp))\n",
    "            in_dims = hp.base_hidden_dims\n",
    "            if self.batch_norms is not None:\n",
    "                self.batch_norms.append(nn.BatchNorm1d(hp.base_hidden_dims))\n",
    "\n",
    "        self.layers.append(GINELayer(hp.base_hidden_dims, hp.base_hidden_dims, hp))\n",
    "\n",
    "    def forward(self, X_n: torch.Tensor, edge_index: torch.Tensor,\n",
    "                edge_attr: torch.Tensor, PE: torch.Tensor) -> torch.Tensor:\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            X_0 = X_n\n",
    "            X_n = layer(X_n, edge_index, edge_attr, PE)\n",
    "            if self.batch_norms is not None and i < len(self.layers) - 1:\n",
    "                X_n = self.batch_norms[i](X_n)\n",
    "            X_n = X_n + X_0  # Residual connection\n",
    "        return X_n\n",
    "\n",
    "\n",
    "class GINEBaseModel(nn.Module):\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(GINEBaseModel, self).__init__()\n",
    "        self.gine = GINE(hp)\n",
    "        self.mlp = MLP(hp.base_hidden_dims, hp.target_dim, hp)\n",
    "        self.pooling = global_mean_pool if hp.pooling == 'mean' else global_add_pool\n",
    "\n",
    "    def forward(self, X_n: torch.Tensor, edge_index: torch.Tensor,\n",
    "                edge_attr: torch.Tensor, PE: torch.Tensor, batch: torch.Tensor) -> torch.Tensor:\n",
    "        X_n = self.gine(X_n, edge_index, edge_attr, PE)\n",
    "        X_n = self.pooling(X_n, batch)\n",
    "        Y_pred = self.mlp(X_n)\n",
    "        return Y_pred.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pearl-model"
   },
   "source": [
    "### 3.5 PEARL GNN Model\n",
    "\n",
    "The complete PEARL model combining all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pearl-model-code"
   },
   "outputs": [],
   "source": [
    "class PEARL_GNN_Model(nn.Module):\n",
    "    def __init__(self, hp: HyperParam):\n",
    "        super(PEARL_GNN_Model, self).__init__()\n",
    "        self.node_features = nn.Embedding(hp.n_node_types, hp.node_emb_dims)\n",
    "        self.positional_encoding = PEARLPositionalEncoder(hp)\n",
    "        self.pe_embedding = nn.Linear(self.positional_encoding.out_dims, hp.node_emb_dims)\n",
    "        self.base_model = GINEBaseModel(hp)\n",
    "\n",
    "    def forward(self, batch: Batch) -> torch.Tensor:\n",
    "        X_n = self.node_features(batch.x.squeeze(dim=1))\n",
    "        PE = self.positional_encoding(batch)\n",
    "        X_n = X_n + self.pe_embedding(PE)\n",
    "        return self.base_model(X_n, batch.edge_index, batch.edge_attr, PE, batch.batch)\n",
    "\n",
    "    def get_param_groups(self) -> List[Dict[str, Any]]:\n",
    "        return [{\"name\": name, \"params\": [param]} for name, param in self.named_parameters()]\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = PEARL_GNN_Model(hp)\n",
    "model.to(hp.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading"
   },
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Load the ZINC dataset with Laplacian transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-loading-code"
   },
   "outputs": [],
   "source": [
    "# Load ZINC dataset\n",
    "root = \"./data/ZINC\"\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = ZINC(root=root, subset=hp.use_subset, split=\"train\", transform=add_laplacian_transform)\n",
    "val_dataset = ZINC(root=root, subset=hp.use_subset, split=\"val\", transform=add_laplacian_transform)\n",
    "test_dataset = ZINC(root=root, subset=hp.use_subset, split=\"test\", transform=add_laplacian_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=hp.train_batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=hp.val_batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hp.test_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"Train: {len(train_dataset)} graphs\")\n",
    "print(f\"Val: {len(val_dataset)} graphs\")\n",
    "print(f\"Test: {len(test_dataset)} graphs\")\n",
    "print(f\"\\nBatch statistics:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-setup"
   },
   "source": [
    "## 5. Training Setup\n",
    "\n",
    "Setup optimizer, scheduler, and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-setup-code"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.get_param_groups(),\n",
    "    lr=hp.learning_rate,\n",
    "    weight_decay=hp.weight_decay\n",
    ")\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "n_total_steps = len(train_loader) * hp.num_epochs\n",
    "\n",
    "def lr_lambda(curr_step: int) -> float:\n",
    "    \"\"\"Linear warmup followed by linear decay.\"\"\"\n",
    "    if curr_step < hp.n_warmup_steps:\n",
    "        return curr_step / max(1, hp.n_warmup_steps)\n",
    "    else:\n",
    "        return max(0.0, (n_total_steps - curr_step) / max(1, n_total_steps - hp.n_warmup_steps))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# Loss functions\n",
    "criterion = nn.L1Loss(reduction=\"mean\")  # MAE for training\n",
    "metric = nn.L1Loss(reduction=\"sum\")  # MAE for evaluation\n",
    "\n",
    "print(f\"Total training steps: {n_total_steps:,}\")\n",
    "print(f\"Warmup steps: {hp.n_warmup_steps}\")\n",
    "print(f\"Initial learning rate: {hp.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-functions"
   },
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-functions-code"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, criterion, device, epoch, num_epochs):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch.y.size(0)\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, loader, metric, device, desc=\"Eval\"):\n",
    "    \"\"\"Evaluate on validation or test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"         [{desc}]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            loss = metric(output, batch.y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def plot_training_progress(train_losses, val_losses, test_losses):\n",
    "    \"\"\"Plot training progress.\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Train MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Training MAE')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, val_losses, 'g-', label='Validation MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Validation MAE')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, test_losses, 'r-', label='Test MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Test MAE')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-loop"
   },
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "Train the PEARL model on ZINC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-loop-code"
   },
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "best_val_loss = 999.0\n",
    "\n",
    "print(f\"\\nStarting training for {hp.num_epochs} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(hp.num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(\n",
    "        model, train_loader, optimizer, scheduler, criterion, hp.device, epoch, hp.num_epochs\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss = evaluate_epoch(model, val_loader, metric, hp.device, desc=\"Val\")\n",
    "    test_loss = evaluate_epoch(model, test_loader, metric, hp.device, desc=\"Test\")\n",
    "    \n",
    "    # Record\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{hp.num_epochs} | \"\n",
    "          f\"Train MAE: {train_loss:.4f} | \"\n",
    "          f\"Val MAE: {val_loss:.4f} | \"\n",
    "          f\"Test MAE: {test_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_pearl_model.pth')\n",
    "        print(f\"  → Best model updated! (Val MAE: {val_loss:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation MAE: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 8. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-code"
   },
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "plot_training_progress(train_losses, val_losses, test_losses)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Best Validation MAE: {best_val_loss:.4f}\")\n",
    "print(f\"Final Train MAE: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Test MAE: {test_losses[-1]:.4f}\")\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load('best_pearl_model.pth'))\n",
    "final_test_loss = evaluate_epoch(model, test_loader, metric, hp.device, desc=\"Final Test\")\n",
    "print(f\"\\nTest MAE with best model: {final_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis"
   },
   "source": [
    "## 9. Model Analysis and Interpretation\n",
    "\n",
    "### 9.1 Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "architecture-summary"
   },
   "outputs": [],
   "source": [
    "print(\"\\nPEARL Architecture Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1. Positional Encoding:\")\n",
    "print(f\"   - Mode: {'B-PEARL (Basis)' if hp.basis else 'R-PEARL (Random)'}\")\n",
    "print(f\"   - PE Dimensions: {hp.pe_dims}\")\n",
    "print(f\"   - Polynomial Filter Order (k): {hp.pearl_k}\")\n",
    "print(f\"   - Number of Samples (R-PEARL): {hp.num_samples if not hp.basis else 'N/A'}\")\n",
    "print(f\"\\n2. GIN Sample Aggregator:\")\n",
    "print(f\"   - Layers: {hp.n_sample_aggr_layers}\")\n",
    "print(f\"   - Hidden Dimensions: {hp.sample_aggr_hidden_dims}\")\n",
    "print(f\"   - Batch Normalization: {hp.gin_sample_aggregator_bn}\")\n",
    "print(f\"\\n3. GINE Base Model:\")\n",
    "print(f\"   - Layers: {hp.n_base_layers}\")\n",
    "print(f\"   - Node Embedding Dimensions: {hp.node_emb_dims}\")\n",
    "print(f\"   - Hidden Dimensions: {hp.base_hidden_dims}\")\n",
    "print(f\"   - Pooling: {hp.pooling}\")\n",
    "print(f\"\\n4. Training Configuration:\")\n",
    "print(f\"   - Learning Rate: {hp.learning_rate}\")\n",
    "print(f\"   - Weight Decay: {hp.weight_decay}\")\n",
    "print(f\"   - Batch Size: {hp.train_batch_size}\")\n",
    "print(f\"   - Epochs: {hp.num_epochs}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "### 9.2 Comparison with Baseline Methods\n",
    "\n",
    "Expected results on ZINC (from paper):\n",
    "\n",
    "| Method | Test MAE |\n",
    "|--------|----------|\n",
    "| GIN | 0.526 |\n",
    "| LSPE | 0.142 |\n",
    "| SignNet/BasisNet | 0.135 |\n",
    "| SPE | 0.122 |\n",
    "| **R-PEARL** | **0.120** |\n",
    "| **B-PEARL** | **0.118** |\n",
    "\n",
    "**Key Advantages of PEARL**:\n",
    "1. **Efficiency**: O(N) or O(N²) vs O(N³) for eigenvector methods\n",
    "2. **Stability**: Robust to graph perturbations\n",
    "3. **Expressiveness**: Beyond 2-FWL test, can count substructures\n",
    "4. **Scalability**: Applicable to large graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **PEARL Implementation**: Complete implementation of R-PEARL and B-PEARL\n",
    "2. **Training Pipeline**: End-to-end training on ZINC dataset\n",
    "3. **Architecture Components**: \n",
    "   - Polynomial filtering for PE generation\n",
    "   - GIN-based sample aggregation\n",
    "   - GINE for molecular property prediction\n",
    "4. **Performance**: Competitive results on molecular property prediction\n",
    "\n",
    "**Next Steps**:\n",
    "- Increase training epochs to 1400 for full convergence\n",
    "- Experiment with different hyperparameters\n",
    "- Try B-PEARL variant (set `hp.basis = True`)\n",
    "- Apply to other graph datasets\n",
    "- Analyze learned positional encodings\n",
    "\n",
    "**References**:\n",
    "- Kanatsoulis et al., \"Learning Efficient Positional Encodings with Graph Neural Networks\", 2025\n",
    "- Code: https://github.com/ehejin/Pearl-PE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
